[project]
name = "liza"
version = "0.1.0"
description = "LiZA : LineariZed Attention Injector (FLA) for Transformers Models"
authors = [
    {name = "fabienfrfr",email = "fabien.furfaro@gmail.com"}
]
license = {text = "Apache 2.0"}
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "torch (>=2.7.0,<3.0.0)",
    "flash-linear-attention (>=0.2.1,<0.3.0)",
    "einops (>=0.8.1,<0.9.0)",
    "pytest (>=8.3.5,<9.0.0)"
]


[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"
